{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Travel With Us - Project","metadata":{}},{"cell_type":"markdown","source":"## Problem Definition\n\n- 'Visit With Us' is a tourism company that currently offers five types of packages to it's customers, namely Basic, Standard, Deluxe, Super Deluxe and King. The Policy Makers of the company wants to establish a viable business model to expand the customer base by introducing a new travel package, the 'Wellness Tourism Package'.\n\n## Objective\n\n- To build and compare Ensemble Models using the data of the existing customers\n- Use the model to target potential customers (including new customers) who are more likely to purchase the new package\n\n## Contents of the dataset\n\n### Customer details\n\n- CustomerID: Unique customer ID\n- ProdTaken: Whether the customer has purchased a package or not (0: No, 1: Yes)\n- Age: Age of customer\n- TypeofContact: How customer was contacted (Company Invited or Self Inquiry)\n- CityTier: City tier depends on the development of a city, population, facilities, and living standards. The categories are ordered i.e. Tier 1 > Tier 2 > Tier 3\n- Occupation: Occupation of customer\n- Gender: Gender of customer\n- NumberOfPersonVisiting: Total number of persons planning to take the trip with the customer\n- PreferredPropertyStar: Preferred hotel property rating by customer\n- MaritalStatus: Marital status of customer\n- NumberOfTrips: Average number of trips in a year by customer\n- Passport: The customer has a passport or not (0: No, 1: Yes)\n- OwnCar: Whether the customers own a car or not (0: No, 1: Yes)\n- NumberOfChildrenVisiting: Total number of children with age less than 5 planning to take the trip with the customer\n- Designation: Designation of the customer in the current organization\n- MonthlyIncome: Gross monthly income of the customer\n\n### Customer interaction data\n\n- PitchSatisfactionScore: Sales pitch satisfaction score\n- ProductPitched: Product pitched by the salesperson\n- NumberOfFollowups: Total number of follow-ups has been done by the salesperson after the sales pitch\n- DurationOfPitch: Duration of the pitch by a salesperson to the customer","metadata":{}},{"cell_type":"code","source":"# Libraries required for data analysis and data visualization\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\npd.set_option(\"display.max_columns\", None)\npd.set_option(\"display.max_rows\", 200)\n\nsns.set(color_codes=True)  # adds background to the graph","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Libraries required for model building and performance evaluation\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    confusion_matrix,\n    classification_report,\n)\n\n# Libraries required to build and tune Decision Tree and Bagging models\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport scipy.stats as stats\nfrom sklearn import metrics\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Libraries required tom build Boosting models\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import StackingClassifier\n\n# Libraries to tune model, get different metric scores\nfrom sklearn import metrics\nfrom sklearn.metrics import (\n    confusion_matrix,\n    classification_report,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n)\nfrom sklearn.model_selection import GridSearchCV","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reading the excel dataset\n\ntravel_data = pd.read_excel(\n   '../input/tourismpackage/Tourism.xlsx', sheet_name='Tourism'\n)  # sheet name containing the actual data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a copy of the dataset\n\ndata = travel_data.copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# viewing the first 10 observations of the dataset\n\ndata.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- CustomerID seems to be all unique\n- NaN values present in Age\n- 6 columns with categorical data\n- ProdTaken, Passport and OwnCar having binary values (0 and 1)\n- Remaing columns are either float or int","metadata":{}},{"cell_type":"code","source":"# viewing the shape of the dataset\n\ndata.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There are a total of 4888 rows and 20 columns","metadata":{}},{"cell_type":"code","source":"# viewing the overall information of the dataset\n\ndata.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There are 7 float type, 7 int type and 6 object type columns in the dataset\n- Memory used is 763.9+ KB\n- Missing values in Age, TypeofContact, DurationOfPitch, NumberOfFollowups, PreferredPropertyStar, NumberOfTrips, NumberOfChildrenVisiting and MonthlyIncome","metadata":{}},{"cell_type":"code","source":"# getting the total count of null values present in the dataset\n\ndata.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There are missing values in 7 of 20 columns ","metadata":{}},{"cell_type":"code","source":"# checking for duplicated rows\n\ndata.duplicated().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- no duplicated observations present in the dataset","metadata":{}},{"cell_type":"markdown","source":"### Fixing the data types","metadata":{}},{"cell_type":"code","source":"# assigning the object type columns to a list\n\ncols = data.select_dtypes(\"object\")\ncols.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting object dataype to category\n\nfor i in cols.columns:\n    data[i] = data[i].astype(\"category\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the datatypes\n\ndata.dtypes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The datatypes are now fixed","metadata":{}},{"cell_type":"code","source":"# checking the statistical summary of the dataset\n\ndata.describe().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- CustomerID is an ID variable and is not useful for predictive modelling\n- Age of the customers ranges from 18 to 61 years and the average age is 37 years\n- DurationOfPitch ranges from 5 to 127 minutes and the average is 15 minutes, indicates skewness or presence of outliers\n- NumberOfPersonVisiting ranges from 1 to 5 and the average is 2 persons\n- NumberOfFollowups ranges from 1 to 6 with an average of 3\n- The average PreferredPropertyStar is 3, whereas the maximum is 5\n- The average NumberOfTrips in a year by customer is 3, whereas the maximum is 22\n- The average PitchSatisfactionScore is 3, whereas it ranges from 1 to 5\n- NumberOfChildrenVisiting is anywhere between 0 and 3 and the average is 1\n- MonthlyIncome of customers ranges from 1000 to 98,000 Rupees, whereas the average is Rs.23,000. The differnece between 75% and the max indicates skewness in the data","metadata":{}},{"cell_type":"code","source":"# summary of categorical columns in the dataset\n\ndata.describe(include=\"category\").T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Need to check for values in Gender and MaritalStatus for any data entry errors\n- Must look at what the unique values are, to get better idea of the data\n- High frequency values in category include Self Enquiry, Salaried, Male customers \n- 'Basic' package is highly preferred by customers. Maybe because most customers are salaried, that they chose the 'Basic' package\n- Married customers are more comparatively. Maybe they tend to travel as family than alone\n- Most commonn designation of customers is 'Executive'","metadata":{}},{"cell_type":"code","source":"data.nunique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- gives an idea on the number of unique values in each column\n- CustomerID is all unique i.e. it's just a unique identification number of the customer and can be dropped while model building\n- There are 3 unique values in Gender and 4 unique values in MaritalStatus, must further check what the values are","metadata":{}},{"cell_type":"code","source":"# making a list of the categorical values in the dataset\n\ncols_cat = data.select_dtypes(\"category\")\ncols_cat.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# viewing the unique values in the categorical columns\n\nfor i in cols_cat.columns:\n    print(\"\\nUnique values in\", i, \"are :\")\n    print(data[i].value_counts())\n    print(\"\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Type of contact is either Self Enquiry or Compaby Invited\n- Salaried customers and Small business owners are more in comparison to Large business owners. There are only 2 Free lancers.\n- Gender column look to have same data entry error that needs to be fixed\n- There are 5 different product packages as mentioned in the data background\n- Marital status includes 4 unique values, wherein unmarried customers may potentially have a partner to travel along\n- Executive and Manager level customers are more in comparison to Senior Managers, AVP and VPs","metadata":{}},{"cell_type":"code","source":"# Fixing data entry error in Gender\n\ndata[\"Gender\"] = data[\"Gender\"].replace(\"Fe Male\", \"Female\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Gender\"].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The data entry error in Gender column is now fixed","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"# Univariate Analysis","metadata":{}},{"cell_type":"code","source":"# Creating an array of color codes to use in this project\n\ncolors = [\"#4178FB\", \"#4DE0FA\", \"#7DFFC6\"]\n\n# Setting custom color palette\n\nsns.set_palette(sns.color_palette(colors))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining a method to print the percentage of data points in the plot\n\n\ndef perc_on_bar(plot, feature):\n    \"\"\"\n    plot\n    feature : categorical feature\n    the function won't work if a column is passed in hue parameter\n    \n    \"\"\"\n    total = len(feature)  # length of the column\n    for p in ax.patches:\n        percentage = \"{:.1f}%\".format(\n            100 * p.get_height() / total\n        )  # percentage of each class of the category\n        x = p.get_x() + p.get_width() / 2 - 0.06  # width of the plot\n        y = p.get_y() + p.get_height()  # height of the plot\n        ax.annotate(\n            percentage,\n            (x, y),\n            # ha=\"center\",\n            # va=\"center\",\n            size=12,\n            # xytext=(0, 3),\n            # textcoords=\"offset points\",\n        )  # annotate the percantage\n    plt.show()  # show the plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining a method to plot histogram and boxplot combined in a single plot\n\n\ndef histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n    \"\"\"\n    Boxplot and histogram combined\n    feature : dataframe column\n    figsize : size of figure (default (12,7))\n    kde : whether to show the density curve (default False)\n    bins : number of bins (default None / auto)\n    \n    \"\"\"\n    f2, (ax_box2, ax_hist2) = plt.subplots(\n        nrows=2,  # Number of rows of the subplot grid=2\n        sharex=True,  # x-axis will be shared among all subplots\n        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n        figsize=figsize,\n    )  # creating the 2 subplots\n    sns.boxplot(\n        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n    )  # boxplot will be created and a star will indicate the mean value of the column\n    sns.histplot(\n        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins\n    ) if bins else sns.histplot(\n        data=data, x=feature, kde=kde, ax=ax_hist2,\n    )  # For histogram\n    ax_hist2.axvline(\n        data[feature].mean(), color=\"purple\", linestyle=\"--\"\n    )  # Add mean to the histogram\n    ax_hist2.axvline(\n        data[feature].median(), color=\"black\", linestyle=\"-\"\n    )  # Add median to the histogram","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Product Taken","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nax = sns.countplot(data[\"ProdTaken\"])\nperc_on_bar(ax, data[\"ProdTaken\"])","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Only 18.8% of the customers have taken the product as opposed to 81.2% of customers who did not take the product. Hence it is an imbalanced classification","metadata":{}},{"cell_type":"markdown","source":"### 2. Age","metadata":{}},{"cell_type":"code","source":"histogram_boxplot(data, \"Age\")","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Age is normally distributed\n- No outliers spotted\n- Slightly right skewed","metadata":{}},{"cell_type":"markdown","source":"### 3. Type of Contact","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nax = sns.countplot(data[\"TypeofContact\"])\nperc_on_bar(ax, data[\"TypeofContact\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 70.5% customers self-enquired as opposed to 29% that were invited by the company","metadata":{}},{"cell_type":"markdown","source":"### 4. City Tier","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7, 5))\nax = sns.countplot(data[\"CityTier\"])\nperc_on_bar(ax, data[\"CityTier\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Maximum number of customers are from Tier 1 cities\n- Followed by Tier 3 and Tier 2-\n- The distribution of the values suggests City Tier can be treated as a 'category'","metadata":{}},{"cell_type":"markdown","source":"### 5. Duration of Pitch","metadata":{}},{"cell_type":"code","source":"histogram_boxplot(data, \"DurationOfPitch\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Mean is around 15\n- Extreme outliers above 125","metadata":{}},{"cell_type":"markdown","source":"### 6. Occupation","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7, 5))\nax = sns.countplot(data[\"Occupation\"])\nperc_on_bar(ax, data[\"Occupation\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As seen in the data summary, Salaried customers are large in number, followed by Small business owners\n- Only about 9% of Large business owners \n- Only 2 Free lancers as seen from the data analysis","metadata":{}},{"cell_type":"markdown","source":"### 7. Gender","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nax = sns.countplot(data[\"Gender\"])\nperc_on_bar(ax, data[\"Gender\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Male customers out number the Female customers","metadata":{}},{"cell_type":"markdown","source":"### 8. Number of Person Visiting","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(9, 5))\nax = sns.countplot(data[\"NumberOfPersonVisiting\"])\nperc_on_bar(ax, data[\"NumberOfPersonVisiting\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 3 persons visiting take up 49.1% of the customers where they could be a family with one child\n- 29% includes two persons visiting followed by 21% of 4 persons visiting","metadata":{}},{"cell_type":"markdown","source":"### 9. Number of Followups","metadata":{}},{"cell_type":"code","source":"histogram_boxplot(data, \"NumberOfFollowups\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Average number of follow ups is 3\n- Maximum number of follow ups is 4\n- Number of outliers around 1 and 6 ","metadata":{}},{"cell_type":"markdown","source":"### 10. Product Pitched","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(9, 5))\nax = sns.countplot(data[\"ProductPitched\"])\nperc_on_bar(ax, data[\"ProductPitched\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 'Basic' package has been pitched for a maximum of 37.7% by the salesperson, followed by 'Deluxe' package with 35%\n- 'Standard' package has been pitched 15% times, 'Super Deluxe' 7% times and the 'King' package with the least of 4.7%\n- The 'King' package, as the names implies may be the most expensive package offered by the company\n- As most of the customers are either salaried or small business owners, it is a possibility that the 'Basic' and 'Deluxe' packages are the ones that are being pitched to them depending on their income","metadata":{}},{"cell_type":"markdown","source":"### 11. Preferred Property Star","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7, 5))\nax = sns.countplot(data[\"PreferredPropertyStar\"])\nperc_on_bar(ax, data[\"PreferredPropertyStar\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Customers generally prefer hotels with rating 3 stars and above\n- 3 star ratings at 61% are a maximum as opposed to 4 star ratings at 18.7% and 5 star ratings at 19.6%\n- It maybe because 4 star and 5 star rated hotels are much expensive in comparison to 3 star rated hotels","metadata":{}},{"cell_type":"markdown","source":"### 12. Marital Status","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nax = sns.countplot(data[\"MaritalStatus\"])\nperc_on_bar(ax, data[\"MaritalStatus\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Married customers are large in number at 47.9%\n- Customers with family tend to travel more on a vacation in comparison with divorced, single and unmarried customers","metadata":{}},{"cell_type":"markdown","source":"### 13. Number of Trips","metadata":{}},{"cell_type":"code","source":"histogram_boxplot(data, \"NumberOfTrips\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Maximum number of trips in a year by a customer is 2\n- Average number of trips in a year by a customer is 3\n- Extreme outliers spotted around 20 times. Maybe they are customers who travel on business purposes.","metadata":{}},{"cell_type":"markdown","source":"### 14. Passport","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nax = sns.countplot(data[\"Passport\"])\nperc_on_bar(ax, data[\"Passport\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 70.9% of cutsomers do not own a passport as opposed to 29.1%\n- This could also be the reason for having a large number of customers to be pitched 'Basic' package by the salesperson","metadata":{}},{"cell_type":"markdown","source":"### 15. Pitch Satisfaction Score","metadata":{}},{"cell_type":"code","source":"histogram_boxplot(data, \"PitchSatisfactionScore\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Pitch satisfaction score ranges from 1 to 5\n- Mean and median are around 3","metadata":{}},{"cell_type":"markdown","source":"### 16. Own Car","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nax = sns.countplot(data[\"OwnCar\"])\nperc_on_bar(ax, data[\"OwnCar\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 62% of customers own a car as opposed to 38% of customers who do not own a car","metadata":{}},{"cell_type":"markdown","source":"### 17. Number of Children Visiting","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nax = sns.countplot(data[\"NumberOfChildrenVisiting\"])\nperc_on_bar(ax, data[\"NumberOfChildrenVisiting\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 42.6% of times there is atleast one child travelling with the customer\n- 27.3% of times there is atleast two children travelling with the customer\n- whereas 22.1% of times, the customers travel without any kids","metadata":{}},{"cell_type":"markdown","source":"### 18. Designation","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(9, 5))\nax = sns.countplot(data[\"Designation\"])\nperc_on_bar(ax, data[\"Designation\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There are a maximum of 37.7% of customers who are Executives, followed by 35.4% of customers who are Managers.\n- There are 15.2% of customers who are Senior Managers \n- 7% AVPs and 4.7% VPs","metadata":{}},{"cell_type":"markdown","source":"### 19. Monthly Income","metadata":{}},{"cell_type":"code","source":"histogram_boxplot(data, \"MonthlyIncome\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Extreme outliers spotted around Rs.1000 and Rs.1 Lakh\n- Mean is around Rs.23000","metadata":{}},{"cell_type":"markdown","source":"# Bivariate Analysis","metadata":{}},{"cell_type":"code","source":"# User defined function to plot stacked bar chart\n\n\ndef stacked_barplot(data, predictor, target):\n    \"\"\"Print the category counts and plot a stacked bar chart\n    data : dataframe\n    predictor : independent variable\n    target : target variable\"\"\"\n\n    count = data[predictor].nunique()\n    sorter = data[target].value_counts().index[-1]\n    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n        by=sorter, ascending=False\n    )\n    print(tab1)\n    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n        by=sorter, ascending=False\n    )\n    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 3, 5))\n    plt.legend(\n        loc=\"lower left\", frameon=False,\n    )\n    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n    plt.xticks(rotation=0)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1 = data.copy().drop(\"CustomerID\", axis=1)\nplt.figure(figsize=(14, 7))\nsns.heatmap(data1.corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Number of person visiting is in positive correlation with the number of children visiting\n- Monthly income is positively correlated to Age. As Age increases, experience increases and hence income is higher with age\n- Product taken is moderately correlated with Passport and Number of followups, Preferred property star\n- Product taken is negatively correlated with Age and Monthly income\n- Monthly income, Number of trips and Number of followups are moderately correlated with Number of people visiting\n- Monthly income is in moderate correlation with Number of children visiting","metadata":{}},{"cell_type":"code","source":"sns.pairplot(data1, hue=\"ProdTaken\")\nplt.show()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Varying distributions of Product taken across different features is visible, which needs further analysis","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Product taken vs Customer information data","metadata":{}},{"cell_type":"code","source":"cust_info_cols1 = data[\n    [\n        \"Age\",\n        \"NumberOfPersonVisiting\",\n        \"NumberOfChildrenVisiting\",\n        \"MonthlyIncome\",\n        \"NumberOfTrips\",\n    ]\n]\n\nplt.figure(figsize=(15, 8))\n\nfor i, variable in enumerate(cust_info_cols1):\n    plt.subplot(2, 3, i + 1)\n    sns.boxplot(data[\"ProdTaken\"], data[variable])\n    plt.tight_layout()\n    plt.title(variable)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Customers in Age range 28 to 42 seems to have purchased the travel package more in number\n- Large number customers who purchased the travel packages travelled in a group of 2 to 3, with an upper whisker at 4\n- The boxplot indicates that customers who purchased the package travel anywhere between 2 to 4 times per year\n- Large number of customers are accompanied by atleast 1 to 2 kids\n- Customers with a minimum monthly income of about 18K/per month and above, seem to show much interest in purchasing travel packages","metadata":{}},{"cell_type":"code","source":"stacked_barplot(data, \"Gender\", \"ProdTaken\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 578 out of 2916 Male customers have purchased a travel package\n- 342 out of 1972 Female customers have purchased a travel package","metadata":{}},{"cell_type":"code","source":"stacked_barplot(data, \"MaritalStatus\", \"ProdTaken\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The highest percentage of customers who actually purchased a package are single\n- Second highest are unmarried customers\n- Lastly are the married and divorced customers","metadata":{}},{"cell_type":"code","source":"stacked_barplot(data, \"Occupation\", \"ProdTaken\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- From the previous analysis, it was seen that Free Lancer customers are too low in number. From this plot it is evident that there are only 2 Free Lancer customers and that they have both bought a travel package.\n- Customers who are large business owners have purchased highest number of packages\n- Followed equally by small business and salaried customers","metadata":{}},{"cell_type":"code","source":"stacked_barplot(data, \"Designation\", \"ProdTaken\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Customers who are Executives seem to have taken the package in highest number followed by Senior Managers and Managers\n- VP and AVP are considerably low in number","metadata":{}},{"cell_type":"code","source":"stacked_barplot(data, \"CityTier\", \"ProdTaken\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- More number of customers from Tier2 and Tier3 cities seem to have purchased travel package in more number in comparison with Tier1","metadata":{}},{"cell_type":"code","source":"stacked_barplot(data, \"OwnCar\", \"ProdTaken\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The percentage of customers who purchased a package is almost the same whether or not they own a car ","metadata":{}},{"cell_type":"code","source":"stacked_barplot(data, \"Passport\", \"ProdTaken\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The percentage of customers who own a passport seem to show more interest in purchasing the travel package in comparison to those who do not own one","metadata":{}},{"cell_type":"code","source":"stacked_barplot(data, \"PreferredPropertyStar\", \"ProdTaken\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Customers perfer a PropertyStar of 3 and above with highest percentage of customers opting a 5 star","metadata":{}},{"cell_type":"markdown","source":"### Product taken vs Customer interaction data","metadata":{}},{"cell_type":"code","source":"pitch_cols = data[[\"DurationOfPitch\", \"PitchSatisfactionScore\", \"NumberOfFollowups\"]]\n\nplt.figure(figsize=(15, 5))\n\nfor i, variable in enumerate(pitch_cols):\n    plt.subplot(1, 3, i + 1)\n    sns.boxplot(data[\"ProdTaken\"], data[variable])\n    plt.tight_layout()\n    plt.title(variable)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Higher the duration of pitch, customer is more likely to purchase the product\n- Pitch satisfaction score does not impact the customer actually purchasing the product\n- Interestingly, higher the number of follow ups, more aren the chances of customer purchasing the product","metadata":{}},{"cell_type":"code","source":"stacked_barplot(data, \"TypeofContact\", \"ProdTaken\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Customers purchasing a product is almost same for different types of contact","metadata":{}},{"cell_type":"code","source":"stacked_barplot(data, \"ProductPitched\", \"ProdTaken\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- If the prodcut pitched is 'Basic', then the customer is most likely to purchase the product. Followed by 'Standard' package.\n- May be the reason being these two packages are less expensive comparatively.","metadata":{}},{"cell_type":"markdown","source":"### Product taken & Product Pitched vs Age, Number of Person Visiting, Number of Children Visiting","metadata":{}},{"cell_type":"code","source":"col1 = data[[\"Age\", \"NumberOfPersonVisiting\", \"NumberOfChildrenVisiting\"]]\n\nplt.figure(figsize=(12, 8))\n\nfor i, variable in enumerate(col1):\n    plt.subplot(2, 2, i + 1)\n    sns.boxplot(x=data[\"ProdTaken\"], y=data[variable], hue=data[\"ProductPitched\"])\n    plt.tight_layout()\n    plt.title(variable)\n    plt.legend(bbox_to_anchor=(1, 1))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observations\n\n**Age** of the customer w.r.t. package purchased :\n- `Basic` - Min 18 and max 50 with IQR between 25 and 35 years of age with outliers until around 60 years\n- `Deluxe`- Min 21 and max 59 years ; IQR between 32 to 43 years of age\n- `King` - Min 27 to max 59 years ; IQR between 42 to 58 years\n- `Standard` - Min 19 to max 61 years ; IQR between 42 to 57 years\n- `Super Deluxe` - Min 39 to max 47 years ; IQR between 40 and 45 years with outliers around 55 years\n\nOverall, `Basic` and `Deluxe` packages are preferred by younger customers in comparision to other packages. `King` package is highly preferred by customers above 40 years, `Standard` package is preferred by customers above 33 years and `Super Deluxe` is higly preferred by customers in their 40s\n\nAverage **Number of person visiting** with customers who purchased travel packages is between 2 and 3 and it is common across all the different packages available.\n\n**Number of children visiting** is same for customers with `Basic`,`Deluxe`,`King` and `Super Deluxe` packages.","metadata":{}},{"cell_type":"markdown","source":"### Product taken & Product Pitched vs Monthly Income, Number of Trips","metadata":{}},{"cell_type":"code","source":"col2 = data[[\"MonthlyIncome\", \"NumberOfTrips\"]]\n\nplt.figure(figsize=(10, 5))\n\nfor i, variable in enumerate(col2):\n    plt.subplot(1, 2, i + 1)\n    sns.boxplot(x=data[\"ProdTaken\"], y=data[variable], hue=data[\"ProductPitched\"])\n    plt.tight_layout()\n    plt.title(variable)\n    plt.legend(bbox_to_anchor=(1, 1))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observations\n\n**Monthly Income** of customers across differnt packages : \n- `Basic` - Min 17K to max 36K with outliers until 39K \n- `Deluxe` - Min 18K to max 37K with outliers until 40K\n- `King` - Min 35K to max 39K with outliers around 20K\n- `Standard` - Min 18K to max 38K with outliers until 40K\n- `Super Deluxe` - Min 28K to max 38.5K with outliers around 21K\n\nOverall, customers with an average monthly income around 22K prefer either `Basic` or `Deluxe` packages ; `King` is preferred by customers with an average monthly income above 35K and `Standard` and `Super Deluxe` packages are preferred by customers with an average monthly income between 22K to 35K.\nHence, we can infer that `Basic` and `Standard` packages are very affordable are they are the basic packages. Whereas, `King` is the most expensive package of all followed by `Super Deluxe` and `Standard`\n\n**Number of trips** per year made by customers who have purchased the travel package is :\n- For `Basic`,`King` and `Standard` package customers, it is min 1 and max 7 with IQR between 3 and 4 \n- `Deluxe` - Min 1 to 8 with an IQR between 3 and 5\n- `Super Deluxe` - 1 to 7 with IQR 1 to 6","metadata":{}},{"cell_type":"markdown","source":"### Product taken & Product Pitched vs Customer Interaction Data","metadata":{}},{"cell_type":"code","source":"pitch_cols = data[\n    [\"DurationOfPitch\", \"NumberOfFollowups\", \"PitchSatisfactionScore\"]\n].columns.tolist()\n\nplt.figure(figsize=(15, 8))\n\nfor i, variable in enumerate(pitch_cols):\n    plt.subplot(2, 2, i + 1)\n    sns.boxplot(x=data[\"ProdTaken\"], y=data[variable], hue=data[\"ProductPitched\"])\n    plt.tight_layout()\n    plt.title(variable)\n    plt.legend(bbox_to_anchor=(1, 1))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observations\n\n**Duration of Pitch** to convince a customer to purchase different packages :\n- `Basic`- Min 6 mins to max 38 mins ; IQR between 10 to 22 mins\n- `Deluxe` - Min 6 to max 38 mins ; IQR between 11 to 35 mins\n- `King` - Around 8-9 mins ; outliers around 29 mins\n- `Standard` - Min 6 to max 38 mins ; IQR between 11 to 36 mins\n- `Super Deluxe` - Min 8 to max 21 mins ; IQR between 15 to 20 mins ; outliers around 30 mins\n\nOverall, more duration is required to convince a customer to purchase `Deluxe` and `Standard` packages \n\n**Numer of Followups** required to convince a customer to purchase different packages :\n- `Basic` - Min 1 to max 6 and IQR between 3 to 5 followups\n- `Deluxe` - Same pattern followed for Basic package\n- `King` - Min 3 to max 6 and IQR between 3 to 5 followups\n- `Standard` - Min 2 to max 6 and IQR between 3 to 4.25 followups ; outliers around 1\n- `Super Deluxe` - Min 1 to max 6 and IQR between 2 to 4 followups\n\nOverall, more number of followups more the chances are that a customer will purchase the travel package\n\n**Pitch satisfaction score** acquired across different packages where the customer actually purchased the package :\n- `Basic` & `Deluxe` - Min 1 to max 5 ; IQR between 2 to 4\n- `King` - Min 2 to max 5 ; IQR between 3 and 4 ; outliers around 1\n- `Standard` - Ranges from 1 ; IQR between 3 and 5 \n- `Super Deluxe` - IQR between 3 and 5\n\nThe pitch satisfaction score is for `Basic` and `Deluxe` packages are the same irrespective of the customer purchasing the package. Maybe the marketing team has to work on it.\nOverall, for `King`, `Standard` and `Super Deluxe` packages, the customers who purchased the packages have given a better satisfaction score than the customers who have not purchased the package.","metadata":{}},{"cell_type":"markdown","source":"# Building Customer Profile for different packages","metadata":{}},{"cell_type":"code","source":"# creating a new dataframe df where the package was actually purchased by the customer\ndf = data[data[\"ProdTaken\"] == 1]\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Grouping data w.r.t different travel packages to build customer profile","metadata":{}},{"cell_type":"markdown","source":"### Listing the statistical summary w.r.t. to the package taken","metadata":{}},{"cell_type":"code","source":"df[df[\"ProductPitched\"] == \"Basic\"].describe().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df[\"ProductPitched\"] == \"Standard\"].describe().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df[\"ProductPitched\"] == \"Deluxe\"].describe().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df[\"ProductPitched\"] == \"Super Deluxe\"].describe().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df[\"ProductPitched\"] == \"King\"].describe().T","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Package vs Categorical data","metadata":{}},{"cell_type":"code","source":"stacked_barplot(df, \"ProductPitched\", \"Gender\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- On an average Male customers have largely purchased `Basic`,`Standard`,`Deluxe` and `Super Deluxe` packages\n- Comparatively Female customers have shown much interest in `King` package","metadata":{}},{"cell_type":"code","source":"stacked_barplot(df, \"ProductPitched\", \"MaritalStatus\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Married customers highly prefer `Standard` and `Deluxe` packages\n- Single customers highly prefer `Basic`, `Super Deluxe` and `King` packages\n- Unmarried customers generally prefer `Basic` and `Deluxe` packages\n- Divorced customers generally prefer the `Basic` package","metadata":{}},{"cell_type":"code","source":"stacked_barplot(df, \"ProductPitched\", \"Occupation\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- `Basic` package is largely preferred by Free lancer and Large business customers\n- `Deluxe`, `King` and `Standard` packages are highly purchased by Small business customers\n- `Super Deluxe` package is preferred by Salaried customers","metadata":{}},{"cell_type":"code","source":"stacked_barplot(df, \"ProductPitched\", \"Designation\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Customers who purchased the travel package `King` are mostly VPs,`Basic` are mostly Executives, `Deluxe` are Managers, `Standard` are Senior Managers and `Super Deluxe` are AVPs.\n- The price range of the packages offered from low to high are namely `Basic, Deluxe, Standard, Super Deluxe and King` that can be inferred from the designation of the customers w.r.t. their income","metadata":{}},{"cell_type":"code","source":"stacked_barplot(df, \"ProductPitched\", \"CityTier\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Customers who purchased `Basic` and `King` packages are mostly from Tier 1 cities\n- Customers who purchased `Standard, Deluxe and Suoer Deluxe` packages are mostly from Tier 3 cities\n- Customers from Tier 2 cities generally prefer the `Basic` package","metadata":{}},{"cell_type":"code","source":"stacked_barplot(df, \"ProductPitched\", \"TypeofContact\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- `Basic, Deluxe and Standard` customers are mostly by their personal interest (Self enquiry)\n- `Super Deluxe` customers are mostly company invited\n- Customers who purchased the `King` package are all Self-enquired","metadata":{}},{"cell_type":"code","source":"stacked_barplot(df, \"ProductPitched\", \"Passport\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 50% of the customers choosing `Basic, King and Super Deluxe` packages have passport\n- Comparatively high proportion of the `Standard and Super Deluxe` customers do not own a passport","metadata":{}},{"cell_type":"code","source":"stacked_barplot(df, \"ProductPitched\", \"OwnCar\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- All `Super Deluxe` customers own a car\n- Most of the `King` customers own a car\n- About half the `Basic and Deluxe` customers do not own a car ","metadata":{}},{"cell_type":"markdown","source":"# Customer Characteristics based on different travel packages","metadata":{}},{"cell_type":"markdown","source":"## BASIC package \n\n- `Age` - Early 20s to early 30s\n- `Type of contact` - Self enquiry\n- `City Tier` - Mostly from tier 1\n- `Occupation` - Salaried\n- `Designation` - Mostly preferred by Executives\n- `Gender` - Preferred by Male customers\n- `Marital status` - Single\n- `Number of person visiting` - 2 to 3 on an average\n- `Number of children visiting` - 1 kid on an average\n- `Passport` - 50% of the customers have a passport\n- `Own car` - 50% of the customers own a car\n- `Preferred property star` - 3 star and above\n- `Number of trips` - 3 trips per year on an average ; Min 1 to max 20 trips/year\n- `Monthly Income` - An average of 20K per month","metadata":{}},{"cell_type":"markdown","source":"## STANDARD package \n\n- `Age` - Early 30s to late 40s\n- `Type of contact` - Mostly self enquiry\n- `City Tier` - Mostly from tier 3\n- `Occupation` - Small business owners and Salaried customers\n- `Designation` - Senior Managers\n- `Gender` - Preferred by Male customers\n- `Marital status` - Married\n- `Number of person visiting` - 2 to 3 on an average\n- `Number of children visiting` - 1 kid on an average\n- `Passport` - Most of them do not have a passport\n- `Own car` - 50% of the customers do not own a car\n- `Preferred property star` - 3 star and above\n- `Number of trips` - 3 trips per year on an average ; Min 1 to max 8 trips/year\n- `Monthly Income` - An average of 26K per month","metadata":{}},{"cell_type":"markdown","source":"## DELUXE package \n\n- `Age` - Early 30s to late 50s\n- `Type of contact` - Only Self enquiry\n- `City Tier` - Mostly from tier 3\n- `Occupation` - Small business\n- `Designation` - Managers\n- `Gender` - Preferred by Male customers\n- `Marital status` - Married\n- `Number of person visiting` - 3 on an average\n- `Number of children visiting` - 1 kid on an average\n- `Passport` - 50% of the customers do not have a passport\n- `Own car` - 75% of the customers do own a car\n- `Preferred property star` - 3 star and above\n- `Number of trips` - 3 trips per year on an average ; Min 1 to max 8 trips/year\n- `Monthly Income` - An average of 23K per month","metadata":{}},{"cell_type":"markdown","source":"## SUPER DELUXE package \n\n- `Age` - Early 30s to late 40s\n- `Type of contact` - Company invited\n- `City Tier` - Mostly from tier 3\n- `Occupation` - Salaried customers\n- `Designation` - AVP\n- `Gender` - Preferred by Male customers\n- `Marital status` - Single\n- `Number of person visiting` - 2 to 3 on an average\n- `Number of children visiting` - 1 kid on an average\n- `Passport` - Most of the customers have passport\n- `Own car` - All customers own a car\n- `Preferred property star` - 3 star and above\n- `Number of trips` - 3 trips per year on an average ; Min 1 to 8 trips/year\n- `Monthly Income` - An average of 29K per month","metadata":{}},{"cell_type":"markdown","source":"## KING package \n\n- `Age` - Early 40s to late 50s\n- `Type of contact` - Self enquiry\n- `City Tier` - Mostly from tier 1\n- `Occupation` - Small business\n- `Designation` - VP\n- `Gender` - Preferred by Female customers\n- `Marital status` - Single\n- `Number of person visiting` - 3 on an average\n- `Number of children visiting` - 1 kid on an average\n- `Passport` - Most of the customers have a passport\n- `Own car` - Most of the customers do own a car\n- `Preferred property star` - 4 star and above\n- `Number of trips` - 2 trips per year on an average ; Min 1 to 7 trips/year\n- `Monthly Income` - An average of 34K per month","metadata":{}},{"cell_type":"markdown","source":"# Key Insights from EDA\n\nCharacteristics of customers who seem to be more interested in purchasing the travel package include :\n\n- customers aged between the late 20s and early 40s\n- customers who travel in a group of 2 to 4 which includes one child (on average)\n- customers from Tier2 and Tier3 cities\n- customers who own a passport\n- customers who are mostly Executives and Managers\n- customers who mostly bought the 'Basic' package after they were pitched\n- Female customers with a higher designation seem to be interested in the 'King' package, whereas Male customers show interest in the 'Super Deluxe'\n- Single, unmarried and divorced customers highly prefer 'Basic' package while married customers prefer more expensive packages, comparatively\n- On average, customers who were followed up three times and above are most likely to purchase the product along with a higher duration of pitch\n- gender, number of children visiting, and owning a car - these factors do not add any significance to the chances of the product being purchased\n- On average, customers who tend to travel three times and above, annually, are more likely to purchase the product\n- customers with an average monthly income ranging between 20K - 25K opt opt for Basic and Standard packages, 23K - 30K opt for Deluxe and Super Deluxe packages and above 33K prefer the King package","metadata":{}},{"cell_type":"markdown","source":"# Missing Value Treatment","metadata":{}},{"cell_type":"code","source":"# checking again for missing values\ndata.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the Age of a customer w.r.t their Designation, Gender and Marital Status\n\ndata.groupby([\"Designation\", \"Gender\", \"MaritalStatus\"])[\"Age\"].median()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing the missing values in Age with the median values as shown in the above analysis\n\ndata[\"Age\"] = data.groupby([\"Designation\", \"Gender\", \"MaritalStatus\"])[\"Age\"].transform(\n    lambda x: x.fillna(x.mean())\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the highest occuring category in Type of contact\n\ndata[\"TypeofContact\"].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing the missing values in Type of Contact with 'Self Enquiry' as it has the highest frequency\n\ndata[\"TypeofContact\"] = data[\"TypeofContact\"].fillna(\"Self Enquiry\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the median value of Duration of Pitch w.r.t. Type of contact and the Product pitched\n\ndata.groupby([\"TypeofContact\", \"ProductPitched\"])[\"DurationOfPitch\"].median()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing the missing values in Duration of Pitch with the median values from the above analysis\n\ndata[\"DurationOfPitch\"] = data.groupby([\"TypeofContact\", \"ProductPitched\"])[\n    \"DurationOfPitch\"\n].transform(lambda x: x.fillna(x.median()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the median value of Number of Followups w.r.t. the Product Taken and the Product Pitched\n\ndata.groupby([\"ProdTaken\", \"ProductPitched\"])[\"NumberOfFollowups\"].median()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing the missing values in NumberOfFollowups with the median values from the above analysis\n\ndata[\"NumberOfFollowups\"] = data.groupby([\"ProdTaken\", \"ProductPitched\"])[\n    \"NumberOfFollowups\"\n].transform(lambda x: x.fillna(x.median()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the median value of Preferred Property Star w.r.t. the Gender and Designation of the customer\n\ndata.groupby([\"Gender\", \"Designation\"])[\"PreferredPropertyStar\"].median()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing the missing values in PreferredPropertyStar with the median values from the above analysis\n\ndata[\"PreferredPropertyStar\"] = data.groupby([\"Gender\", \"Designation\"])[\n    \"PreferredPropertyStar\"\n].transform(lambda x: x.fillna(x.median()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the median value of Number Of Trips w.r.t. Gender, Marital Status and Designation\n\ndata.groupby([\"Gender\", \"MaritalStatus\", \"Designation\"])[\"NumberOfTrips\"].median()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing the missing values in NumberOfTrips with the median values from the above analysis\n\ndata[\"NumberOfTrips\"] = data.groupby([\"Gender\", \"MaritalStatus\", \"Designation\"])[\n    \"NumberOfTrips\"\n].transform(lambda x: x.fillna(x.median()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the Number of Children Visiting w.r.t. Marital Status, Product Pitched and the Number of Person Visiting\n\ndata.groupby([\"MaritalStatus\", \"ProductPitched\", \"NumberOfPersonVisiting\"])[\n    \"NumberOfChildrenVisiting\"\n].median()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing the missing values in NumberOfChildrenVisiting with the median values from the above analysis\n\ndata[\"NumberOfChildrenVisiting\"] = data.groupby(\n    [\"MaritalStatus\", \"ProductPitched\", \"NumberOfPersonVisiting\"]\n)[\"NumberOfChildrenVisiting\"].transform(lambda x: x.fillna(x.median()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the Monthly Income w.r.t. the Occupation, Designation and Gender of the customer\n\ndata.groupby([\"Occupation\", \"Designation\", \"Gender\"])[\"MonthlyIncome\"].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing the missing values in MonthlyIncome with the mean values from the above analysis\n\ndata[\"MonthlyIncome\"] = data.groupby([\"Occupation\", \"Designation\", \"Gender\"])[\n    \"MonthlyIncome\"\n].transform(lambda x: x.fillna(x.mean()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for the missing values again\n\ndata.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- No more missing values in the dataset ; they're all fixed","metadata":{}},{"cell_type":"markdown","source":"# Outlier Detection","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a list of numerical columns\n\nnum_col = [\"DurationOfPitch\", \"NumberOfFollowups\", \"NumberOfTrips\", \"MonthlyIncome\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Boxplots of numerical columns to view the outliers\n\nplt.figure(figsize=(20, 7))\n\nfor i, variable in enumerate(num_col):\n    plt.subplot(1, 4, i + 1)\n    plt.boxplot(data[variable], whis=1.5)\n    plt.tight_layout()\n    plt.title(variable)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outlier Treatment","metadata":{}},{"cell_type":"markdown","source":"- As seen in the EDA, the columns DurationOfPitch, NumberOfFollowups, NumberOfTrips and MonthlyIncome columns have outliers. However, I choose not to treat the outliers as in real life the data will have outliers and I want the model learn the variations in the data distribution. Also, the **Bagging and Boosting** algorithms are robust and they can handle outliers.","metadata":{}},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"markdown","source":"- Since the objective is to build models on data of the existing customers which can be used to target new customers, we can drop the customer interaction data from the dataset as those features will not be available for new customers.\n- Also, CustomerID will not be of much help in model building and hence dropping that too.","metadata":{}},{"cell_type":"code","source":"data.drop(\n    [\n        \"CustomerID\",\n        \"DurationOfPitch\",\n        \"NumberOfFollowups\",\n        \"ProductPitched\",\n        \"PitchSatisfactionScore\",\n    ],\n    axis=1,\n    inplace=True,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the overall information of the dataset\ndata.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As seen in the EDA, the distribution of City Tier can be treated as a category. Therefore doing the same\n\ndata[\"CityTier\"] = data[\"CityTier\"].astype(\"category\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the dataset again\ndata.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The dataset now consists of 6 category, 5 float and 4 integer type columns with no null values. The dataset is now ready for model building","metadata":{}},{"cell_type":"markdown","source":"## Split Data","metadata":{}},{"cell_type":"code","source":"X = data.drop([\"ProdTaken\"], axis=1)\ny = data[\"ProdTaken\"]\n\n# creating dummy variables for categorical features\nX = pd.get_dummies(X, drop_first=True)\n\n# splitting the data into train and test sets\n# using 'stratify' parameter as the distribution of the target classes is imbalanced\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=1, stratify=y\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of Training set :\", X_train.shape)\nprint(\"Shape of test set :\", X_test.shape)\nprint(\"\\n Percentage of classes in training set :\")\nprint(y_train.value_counts(normalize=True))\nprint(\"\\n Percentage of classes in test set :\")\nprint(y_test.value_counts(normalize=True))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model evaluation criterion","metadata":{}},{"cell_type":"markdown","source":"#### Model can make wrong predictions such as :\n\n1. Predicting a customer will purchase a travel package but in reality the customer does not purchase one.\n2. Predicting a customer will not purchase a travel package but in reality the customer will purchase the travel package.\n\n#### Prediction of concern :\n\nThe second prediction is our major concern as the 'Visit With Us' travel company plans to launch a new tourism package and wants to harness the available data to make the marketing expenditure more efficient. In order to do so, mistakes in the second prediction (i.e. False negatives) have to be considerably reduced.\n\n#### How to reduce False Negatives :\n\nRecall score should be maximized. Greater the Recall score, higher the chances of predicting the potential customers who may purchase the new travel package.","metadata":{}},{"cell_type":"code","source":"# defining a function to plot the confusion matrix to visualize the model performance\n\n\ndef confusion_matrix_sklearn(model, predictors, target):\n    \"\"\"\n    To plot the confusion_matrix with percentages\n\n    model: classifier\n    predictors: independent variables\n    target: dependent variable\n    \"\"\"\n    y_pred = model.predict(predictors)\n    cm = confusion_matrix(target, y_pred)\n    labels = np.asarray(\n        [\n            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n            for item in cm.flatten()\n        ]\n    ).reshape(2, 2)\n\n    plt.figure(figsize=(6, 4))\n    sns.heatmap(cm, annot=labels, fmt=\"\")\n    plt.ylabel(\"True label\")\n    plt.xlabel(\"Predicted label\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining a function to compute different metrics to check performance of a classification model built using sklearn\n\n\ndef model_performance_classification(model, predictors, target):\n    \"\"\"\n    Function to compute different metrics to check classification model performance\n\n    model: classifier\n    predictors: independent variables\n    target: dependent variable\n    \"\"\"\n\n    # predicting using the independent variables\n    pred = model.predict(predictors)\n\n    acc = accuracy_score(target, pred)  # to compute Accuracy\n    recall = recall_score(target, pred)  # to compute Recall\n    precision = precision_score(target, pred)  # to compute Precision\n    f1 = f1_score(target, pred)  # to compute F1-score\n\n    # creating a dataframe of metrics\n    df_perf = pd.DataFrame(\n        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n        index=[0],\n    )\n    return df_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building - Bagging ","metadata":{}},{"cell_type":"markdown","source":"## Decision Tree","metadata":{}},{"cell_type":"markdown","source":"####  with default parameters","metadata":{}},{"cell_type":"code","source":"dtree = DecisionTreeClassifier(random_state=1)\ndtree.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(dtree, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtree_train_perf = model_performance_classification(dtree, X_train, y_train)\ndtree_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtree_test_perf = model_performance_classification(dtree, X_test, y_test)\ndtree_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The decision tree is fully grown, hence overfitting","metadata":{}},{"cell_type":"markdown","source":"#### Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"# Choose the type of classifier.\ndtree_tuned = DecisionTreeClassifier(class_weight={0: 0.18, 1: 0.82}, random_state=1)\n\n# Grid of parameters to choose from\nparameters = {\n    \"max_depth\": [1, 4, 7, 15],\n    \"min_samples_leaf\": [2, 3, 5],\n    \"max_leaf_nodes\": [5, 7, 10, 15],\n}\n\n# Run the grid search\ngrid_obj = GridSearchCV(dtree_tuned, parameters, scoring=\"recall\")\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\ndtree_tuned = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data\ndtree_tuned.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(dtree_tuned, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtree_tuned_train_perf = model_performance_classification(dtree_tuned, X_train, y_train)\ndtree_tuned_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtree_tuned_test_perf = model_performance_classification(dtree_tuned, X_test, y_test)\ndtree_tuned_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The model is generalising well with tuned parameters","metadata":{}},{"cell_type":"markdown","source":"### Visualizing the Decision Tree","metadata":{}},{"cell_type":"code","source":"# creating a list of column names\nfeature_names = X_train.columns.to_list()\n\nplt.figure(figsize=(15, 10))\nout = tree.plot_tree(\n    dtree_tuned,\n    feature_names=feature_names,\n    filled=True,\n    fontsize=9,\n    node_ids=False,\n    class_names=None,\n)\n\nfor o in out:\n    arrow = o.arrow_patch\n    if arrow is not None:\n        arrow.set_edgecolor(\"black\")\n        arrow.set_linewidth(1)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importance of features in the tree building\nprint(\n    pd.DataFrame(\n        dtree_tuned.feature_importances_, columns=[\"Imp\"], index=X_train.columns\n    ).sort_values(by=\"Imp\", ascending=False)\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances = dtree_tuned.feature_importances_\nindices = np.argsort(importances)\n\nplt.figure(figsize=(12, 12))\nplt.title(\"Feature Importances\")\nplt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\nplt.xlabel(\"Relative Importance\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Passport feature is given highest importance in tree building followed by Designation_Executive, CityTier3 and Age","metadata":{}},{"cell_type":"markdown","source":"## Bagging Classifier","metadata":{}},{"cell_type":"markdown","source":"#### with default parameters","metadata":{}},{"cell_type":"code","source":"bagging = BaggingClassifier(random_state=1)\nbagging.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(bagging, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bagging_train_perf = model_performance_classification(bagging, X_train, y_train)\nbagging_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bagging_test_perf = model_performance_classification(bagging, X_test, y_test)\nbagging_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Bagging classifier is overfitting on the training set and performing poorly on the test set in terms of Recall","metadata":{}},{"cell_type":"markdown","source":"#### With Hypertuned Decision Tree as base estimator","metadata":{}},{"cell_type":"code","source":"bagging_dtree_tuned = BaggingClassifier(base_estimator=dtree_tuned, random_state=1)\nbagging_dtree_tuned.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(bagging_dtree_tuned, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bagging_dtree_tuned_train_perf = model_performance_classification(\n    bagging_dtree_tuned, X_train, y_train\n)\nbagging_dtree_tuned_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bagging_dtree_tuned_test_perf = model_performance_classification(\n    bagging_dtree_tuned, X_test, y_test\n)\nbagging_dtree_tuned_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Bagging classifier with tuned decision tree as the base estimator is giving a genralized model. The metrics are still low. Must try hyperparameter tuning to check for better Recall on the test data","metadata":{}},{"cell_type":"markdown","source":"#### Hyperparameter Tuning\n\n- Hypertuning the bagging classifier with tuned decision tree as base estimator since it is giving a more generalized model","metadata":{}},{"cell_type":"code","source":"# grid search for bagging classifier\ncl1 = dtree_tuned\nparam_grid = {\n    \"base_estimator\": [cl1],\n    \"max_samples\": [0.7, 0.8, 0.9, 1],\n    \"n_estimators\": [5, 7, 10, 15, 20, 30, 40, 51, 101],\n    \"max_features\": [0.7, 0.8, 0.9, 1],\n}\n\ngrid = GridSearchCV(\n    BaggingClassifier(random_state=1, bootstrap=True),\n    param_grid=param_grid,\n    scoring=\"recall\",\n    cv=5,\n)\ngrid.fit(X_train, y_train)\n\n# getting the best estimator\nbagging_tuned = grid.best_estimator_\nbagging_tuned.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(bagging_tuned, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bagging_tuned_train_perf = model_performance_classification(\n    bagging_tuned, X_train, y_train\n)\nbagging_tuned_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bagging_tuned_test_perf = model_performance_classification(\n    bagging_tuned, X_test, y_test\n)\nbagging_tuned_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Tuned bagging classifier is giving a generalized model with a very good Recall scores in both train and test sets. However, it is performing poorly in terms of Precision score","metadata":{}},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"markdown","source":"#### with default parameters","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(random_state=1)\nrf.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(rf, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_train_perf = model_performance_classification(rf, X_train, y_train)\nrf_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_test_perf = model_performance_classification(rf, X_test, y_test)\nrf_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Random Forest is overfitting on the training data and is performing poorly on the test data in terms of Recall","metadata":{}},{"cell_type":"markdown","source":"#### Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"# Choose the type of classifier\nrf_estimator = RandomForestClassifier(random_state=1)\n\n# Grid of parameters to choose from\nparameters = {\n    \"n_estimators\": [150, 200, 250],\n    \"min_samples_leaf\": np.arange(5, 10),\n    \"max_features\": np.arange(0.2, 0.7, 0.1),\n    \"max_samples\": np.arange(0.3, 0.7, 0.1),\n}\n\n# Run the grid search\ngrid_obj = GridSearchCV(rf_estimator, parameters, scoring=\"recall\", cv=5)\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nrf_tuned = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data\nrf_tuned.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(rf_tuned, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_tuned_train_perf = model_performance_classification(rf_tuned, X_train, y_train)\nrf_tuned_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_tuned_test_perf = model_performance_classification(rf_tuned, X_test, y_test)\nrf_tuned_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Tuned random forest model is generalizing in comparison to the model with default parameters. However, it is performing poorly in terms of the Recall score","metadata":{}},{"cell_type":"markdown","source":"### Feature importance of Random Forest","metadata":{}},{"cell_type":"code","source":"# Importance of features in the tree building\nprint(\n    pd.DataFrame(\n        rf_tuned.feature_importances_, columns=[\"Imp\"], index=X_train.columns\n    ).sort_values(by=\"Imp\", ascending=False)\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances = rf_tuned.feature_importances_\nindices = np.argsort(importances)\n\nplt.figure(figsize=(12, 12))\nplt.title(\"Feature Importances\")\nplt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\nplt.xlabel(\"Relative Importance\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Random Forest Classifier has given highest importance to Monthly Income and Age\n- Followed by Passport, Number of trips and Designation_Executive\n- Designation_VP has been given the least imortance","metadata":{}},{"cell_type":"markdown","source":"## Comparison of Models - Bagging","metadata":{}},{"cell_type":"code","source":"# training performance comparison\n\nmodels_train_comp_df = pd.concat(\n    [\n        dtree_train_perf.T,\n        dtree_tuned_train_perf.T,\n        bagging_train_perf.T,\n        bagging_dtree_tuned_train_perf.T,\n        bagging_tuned_train_perf.T,\n        rf_train_perf.T,\n        rf_tuned_train_perf.T,\n    ],\n    axis=1,\n)\nmodels_train_comp_df.columns = [\n    \"Decision Tree\",\n    \"Decision Tree Tuned\",\n    \"Bagging Classifier\",\n    \"Bagging Classifier with dtree_tuned base estimator\",\n    \"Bagging Classifier Tuned\",\n    \"Random Forest\",\n    \"Random Forest Tuned\",\n]\nprint(\"Training performance comparison:\")\nmodels_train_comp_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing performance comparison\n\nbagging_models_test_comp_df = pd.concat(\n    [\n        dtree_test_perf.T,\n        dtree_tuned_test_perf.T,\n        bagging_test_perf.T,\n        bagging_dtree_tuned_test_perf.T,\n        bagging_tuned_test_perf.T,\n        rf_test_perf.T,\n        rf_tuned_test_perf.T,\n    ],\n    axis=1,\n)\nbagging_models_test_comp_df.columns = [\n    \"Decision Tree\",\n    \"Decision Tree Tuned\",\n    \"Bagging Classifier\",\n    \"Bagging Classifier with dtree_tuned base estimator\",\n    \"Bagging Classifier Tuned\",\n    \"Random Forest\",\n    \"Random Forest Tuned\",\n]\nprint(\"\\nTesting performance comparison:\")\nbagging_models_test_comp_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Performance - Observations (Bagging)\n\n- Overfit models - Desicion tree, Bagging Classifier and Random Forest\n- Generalized models - Tuned decision tree, Bagging Classifier with tuned decision tree as the base estimator, tuned Bagging Classifier and tuned Random Forest models\n- Tuned Bagging Classifier gives the highest Recall in the test set\n- The business may choose tuned Decision Tree for a good Recall with a better Precision score","metadata":{}},{"cell_type":"markdown","source":"# Model Building - Boosting","metadata":{}},{"cell_type":"markdown","source":"## AdaBoost Classifier","metadata":{}},{"cell_type":"markdown","source":"#### With default parameters","metadata":{}},{"cell_type":"code","source":"abc = AdaBoostClassifier(random_state=1)\nabc.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(abc, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abc_train_perf = model_performance_classification(abc, X_train, y_train)\nabc_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abc_test_perf = model_performance_classification(abc, X_test, y_test)\nabc_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- AdaBoost is generalizing well but it is giving very poor performance in terms of Recall","metadata":{}},{"cell_type":"markdown","source":"#### Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"# choose the type of classifier\nabc_tuned = AdaBoostClassifier(random_state=1)\n\n# Grid of parameters\nparameters = {  # trying different max_depth for base_estimator\n    \"base_estimator\": [\n        DecisionTreeClassifier(max_depth=1, random_state=1),\n        DecisionTreeClassifier(max_depth=2, random_state=1),\n        DecisionTreeClassifier(max_depth=3, random_state=1),\n    ],\n    \"n_estimators\": [100],  # np.arange(10, 110, 10),\n    \"learning_rate\": np.arange(0.1, 2, 0.1),\n}\n\n# Run the grid search\ngrid_obj = GridSearchCV(abc_tuned, parameters, scoring=\"recall\", cv=5)\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nabc_tuned = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data\nabc_tuned.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(abc_tuned, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abc_tuned_train_perf = model_performance_classification(abc_tuned, X_train, y_train)\nabc_tuned_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abc_tuned_test_perf = model_performance_classification(abc_tuned, X_test, y_test)\nabc_tuned_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Tuned adaboost classifier is overfitting on the trainind data. However, Recall has improved in comparison to the model with default parameters","metadata":{}},{"cell_type":"code","source":"# Importance of features in the tree building\nprint(\n    pd.DataFrame(\n        abc_tuned.feature_importances_, columns=[\"Imp\"], index=X_train.columns\n    ).sort_values(by=\"Imp\", ascending=False)\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances = abc_tuned.feature_importances_\nindices = np.argsort(importances)\nfeature_names = list(X.columns)\n\nplt.figure(figsize=(12, 12))\nplt.title(\"Feature Importances\")\nplt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\nplt.xlabel(\"Relative Importance\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Monthly Income is given the highest feature importance by the tuned Adaboost classifier, followed by Age and Number of trips. \n- Passport, which was given much higher importance by the Bagging models is given lower importance here","metadata":{}},{"cell_type":"markdown","source":"## Gradient Boosting Classifier","metadata":{}},{"cell_type":"markdown","source":"#### With default parameters","metadata":{}},{"cell_type":"code","source":"gbc = GradientBoostingClassifier(random_state=1)\ngbc.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(gbc, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc_train_perf = model_performance_classification(gbc, X_train, y_train)\ngbc_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc_test_perf = model_performance_classification(gbc, X_test, y_test)\ngbc_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The model is giving generalized scores on train and test sets. The Recall score is better than the Adaboost model with default parameters.","metadata":{}},{"cell_type":"markdown","source":"#### Hyperparameter tuning\n\n- Hyperparameter tuning the gradient boost model with AdaBoost Classifier as the base estimator as it gave a generalized model","metadata":{}},{"cell_type":"code","source":"gbc_tuned = GradientBoostingClassifier(\n    init=AdaBoostClassifier(random_state=1), random_state=1\n)\n\n# Grid of parameters to choose from\nparameters = {\n    \"n_estimators\": [250],\n    \"subsample\": [0.8, 0.9, 1],\n    \"max_features\": [0.7, 0.8, 0.9, 1],\n}\n\n# Run the grid search\ngrid_obj = GridSearchCV(gbc_tuned, parameters, scoring=\"recall\", cv=5)\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\ngbc_tuned = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data.\ngbc_tuned.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(gbc_tuned, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc_tuned_train_perf = model_performance_classification(gbc_tuned, X_train, y_train)\ngbc_tuned_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc_tuned_test_perf = model_performance_classification(gbc_tuned, X_test, y_test)\ngbc_tuned_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Recall has improved a little compared to the model with default parameters","metadata":{}},{"cell_type":"code","source":"# Importance of features in the tree building\nprint(\n    pd.DataFrame(\n        gbc_tuned.feature_importances_, columns=[\"Imp\"], index=X_train.columns\n    ).sort_values(by=\"Imp\", ascending=False)\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances = gbc_tuned.feature_importances_\nindices = np.argsort(importances)\nfeature_names = list(X.columns)\n\nplt.figure(figsize=(12, 12))\nplt.title(\"Feature Importances\")\nplt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\nplt.xlabel(\"Relative Importance\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The feature with highest importance are same as the feature importances given by the tuned Random Forest model","metadata":{}},{"cell_type":"markdown","source":"## XGBoost Classifier","metadata":{}},{"cell_type":"markdown","source":"#### Default parameter","metadata":{}},{"cell_type":"code","source":"xgb = XGBClassifier(random_state=1, eval_metric=\"logloss\")\nxgb.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(xgb, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_train_perf = model_performance_classification(xgb, X_train, y_train)\nxgb_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_test_perf = model_performance_classification(xgb, X_test, y_test)\nxgb_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- XGBoost with default paramerts is overfitting on the training data and is giving a low Recall score on the test data","metadata":{}},{"cell_type":"markdown","source":"#### Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"# choose the type of classifier\nxgb_tuned = XGBClassifier(random_state=1, eval_metric=\"logloss\")\n\n# Grid of parameters\nparameters = {\n    \"n_estimators\": np.arange(50, 100, 20),\n    \"scale_pos_weight\": [5],\n    \"subsample\": [0.9, 1],\n    \"learning_rate\": [0.1],\n    \"gamma\": [3],\n    \"colsample_bytree\": [0.5, 0.7, 0.9, 1],\n    \"colsample_bylevel\": [0.5, 0.7, 0.9, 1],\n}\n\n# Run the grid search\ngrid_obj = GridSearchCV(xgb_tuned, parameters, scoring=\"recall\", cv=5)\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nxgb_tuned = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data\nxgb_tuned.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(xgb_tuned, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_tuned_train_perf = model_performance_classification(xgb_tuned, X_train, y_train)\nxgb_tuned_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_tuned_test_perf = model_performance_classification(xgb_tuned, X_test, y_test)\nxgb_tuned_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The model is overfit a little\n- However, hyperparamter tuned XGBoost classifier is giving the highest Recall highest amongst all the Boosting algorithms","metadata":{}},{"cell_type":"code","source":"# Importance of features in the tree building\nprint(\n    pd.DataFrame(\n        xgb_tuned.feature_importances_, columns=[\"Imp\"], index=X_train.columns\n    ).sort_values(by=\"Imp\", ascending=False)\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances = xgb_tuned.feature_importances_\nindices = np.argsort(importances)\nfeature_names = list(X.columns)\n\nplt.figure(figsize=(12, 12))\nplt.title(\"Feature Importances\")\nplt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\nplt.xlabel(\"Relative Importance\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Passport is given the highset feature importance by the tuned XGBoost classifier\n- MaritalStatus_Single, Designation_Executive and CityTier_3 are given second highest importance","metadata":{}},{"cell_type":"markdown","source":"## Stacking Classifier","metadata":{}},{"cell_type":"code","source":"# Building a stacking model with tuned random forest, bagging classifier, tuned gradient boosting classifier and tuned XGBoost classifier as the final predictor\n\nestimators = [\n    (\"Random Forest tuned\", rf_tuned),\n    (\"Bagging Classifier\", bagging),\n    (\"Gradient Boosting Tuned\", gbc_tuned),\n]\nfinal_estimator = xgb_tuned\n\nstacking_classifier = StackingClassifier(\n    estimators=estimators, final_estimator=final_estimator\n)\nstacking_classifier.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_sklearn(stacking_classifier, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacking_train_perf = model_performance_classification(\n    stacking_classifier, X_train, y_train\n)\nstacking_train_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacking_test_perf = model_performance_classification(\n    stacking_classifier, X_test, y_test\n)\nstacking_test_perf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The model is a little overfit\n- However, Stacking classifier is giving the highest Recall in the test set","metadata":{}},{"cell_type":"markdown","source":"## Comparison of Models - Boosting","metadata":{}},{"cell_type":"code","source":"# training performance comparison\n\nboosting_models_train_comp_df = pd.concat(\n    [\n        abc_train_perf.T,\n        abc_tuned_train_perf.T,\n        gbc_train_perf.T,\n        gbc_tuned_train_perf.T,\n        xgb_train_perf.T,\n        xgb_tuned_train_perf.T,\n        stacking_train_perf.T,\n    ],\n    axis=1,\n)\nboosting_models_train_comp_df.columns = [\n    \"AdaBoost Classifier\",\n    \"AdaBoost Classifier Tuned\",\n    \"Gradient Boosting Classifier\",\n    \"Gradient Boosting Classifier Tuned\",\n    \"XGBoost Classifier\",\n    \"XGBoost Classifier Tuned\",\n    \"Stacking Classifier\",\n]\nprint(\"Training performance comparison:\")\nboosting_models_train_comp_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing performance comparison\n\nboosting_models_test_comp_df = pd.concat(\n    [\n        abc_test_perf.T,\n        abc_tuned_test_perf.T,\n        gbc_test_perf.T,\n        gbc_tuned_test_perf.T,\n        xgb_test_perf.T,\n        xgb_tuned_test_perf.T,\n        stacking_test_perf.T,\n    ],\n    axis=1,\n)\nboosting_models_test_comp_df.columns = [\n    \"AdaBoost Classifier\",\n    \"AdaBoost Classifier Tuned\",\n    \"Gradient Boosting Classifier\",\n    \"Gradient Boosting Classifier Tuned\",\n    \"XGBoost Classifier\",\n    \"XGBoost Classifier Tuned\",\n    \"Stacking Classifier\",\n]\nprint(\"Training performance comparison:\")\nboosting_models_test_comp_df","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Performance - Observations (Boosting)\n\n- AdaBoost classifier and Gradient Boost Classifier are most generalized models but, they perform poorly in terms of Recall \n- XGBoost and Stacking models are little overfit but they are giving the highest Recall scores in the test set\n- We can also look into tuning the XGBoost classifier with different parameters and stacking classifier with different weak learners to get more generalized models\n- Business may choose the stacking model for highest Recall or tuned XGBoost model for a higher Recall with a little better Precision score\n\n**Note** : Have not added class_weight for Boosting algorithms as they gave much lower Recall scores while tuning","metadata":{}},{"cell_type":"markdown","source":"# Business Insights and Recommendations","metadata":{}},{"cell_type":"markdown","source":"- The business can use this predictive model to \n    - identify potential customers who may purchase the travel packages\n    - potential new customers who may purchase the packages that are offered / packages that are newly launched\n    - the features that drive the customer to buy the package\n- Features that impact Product taken - Passport, Designation, Marital Status, City Tier, Monthly Income, Age and Number of trips annually\n    - customers who own a passport show more interesting in buying the product\n    - customers with Designation Executive, Marital Status single and City Tier 3 should be our target customers\n    - customers with Monthly Income 15K to 25K, Age 25 to 40 show more interest in buying a travel package\n    - larger the number of trips taken by a customer annually, higher is the chances of customer buying the package\n- The marketing team should focus on \n    - higher duration of pitch by salesperson with the customer\n    - do multiple followups with the customer\n    - encourage customers to get passport\n    - market and company invite customers for 'King' package \n- Once the 'Wellness Package' is launched, the business can collect data on customer information, their preference, product satisfaction and customer interaction so as to enable data analysis for better results","metadata":{}}]}